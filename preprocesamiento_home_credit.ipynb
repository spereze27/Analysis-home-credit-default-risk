{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3372d4",
   "metadata": {},
   "source": [
    "# Configuraci칩n inicial y librer칤as\n",
    "\n",
    "Se importan las librer칤as necesarias para llevar a cabo el preprocesamiento del dataset. Este conjunto de datos requiere transformaci칩n de fechas, codificaci칩n de variables categ칩ricas, creaci칩n de nuevas caracter칤sticas y manejo de valores faltantes. A continuaci칩n, se explican brevemente las librer칤as utilizadas:\n",
    "\n",
    "- `pandas`: manipulaci칩n de datos estructurados.\n",
    "- `numpy`: operaciones num칠ricas y matem치ticas.\n",
    "- `scipy.stats`: operaciones estad칤sticas como la moda.\n",
    "- `sklearn.preprocessing.LabelEncoder`: codificaci칩n de variables categ칩ricas.\n",
    "- `matplotlib.pyplot`: visualizaci칩n b치sica (opcional).\n",
    "- `warnings`: suprime advertencias innecesarias en la ejecuci칩n.\n",
    "- `gc` (garbage collector): optimiza el uso de memoria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4876b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer칤as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# Se configura pandas para mostrar todas las columnas\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Ignorar advertencias\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Activar garbage collector para habilitar la recoleccion de basura, esto mejora el rendimiento en ambientes \n",
    "# que tienen un uso intensivo de memoria como lo es el caso del manejo de los datasets de la actividad desarrollada\n",
    "\n",
    "gc.enable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada1f87",
   "metadata": {},
   "source": [
    "# Funciones para el preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748dd303",
   "metadata": {},
   "source": [
    "### Funci칩n para contar valores nulos\n",
    "La funci칩n `contar_nulos(data)` permite encontrar valores faltantes en un conjunto de datos. Su objetivo es identificar qu칠 columnas tienen datos incompletos, cu치ntos valores faltan y qu칠 porcentaje representan respecto al total de registros.\n",
    "\n",
    "Primero, calcula la cantidad total de valores nulos en cada columna utilizando `data.isnull().sum()`, que cuenta los `True` para cada celda nula. Luego, ordena estas cantidades de forma descendente para priorizar las columnas m치s problem치ticas.\n",
    "\n",
    "A continuaci칩n, calcula el porcentaje de nulos dividiendo cada total de nulos por el n칰mero total de filas del `DataFrame`, y multiplica por 100 para expresarlo en porcentaje. Tambi칠n se ordenan los resultados de mayor a menor.\n",
    "\n",
    "Ambas series (total y porcentaje) se combinan en un solo `DataFrame` usando `pd.concat.\n",
    "\n",
    "Por 칰ltimo, se filtran las columnas con valores nulos, devolviendo 칰nicamente aquellas que presentan al menos un valor faltante. Esto permite enfocarse exclusivamente en las variables que requieren alg칰n tipo de tratamiento durante la limpieza de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afb1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contar_nulos(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    porcentaje = (data.isnull().sum() / len(data) * 100).sort_values(ascending=False)\n",
    "    tabla = pd.concat([total, porcentaje], axis=1, keys=[\"Total de nulos\", \"Porcentaje\"])\n",
    "    return tabla[tabla[\"Total de nulos\"] > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49015e99",
   "metadata": {},
   "source": [
    "### Funci칩n convertir_dias\n",
    "La funci칩n `convertir_dias(data, columnas, divisor=12, redondear=True, reemplazar=False)` se utiliza para transformar columnas que contienen valores de tiempo expresados en d칤as negativos, como por ejemplo DAYS_BIRTH o DAYS_EMPLOYED, en unidades m치s interpretables como meses o a침os.\n",
    "\n",
    "El par치metro columnas especifica la lista de variables que se desean transformar. El par치metro `divisor` determina en qu칠 unidad se har치 la conversi칩n (en este caso 12, para convertirlo a meses).\n",
    "\n",
    "Dentro del bucle, se invierte el signo del valor (porque los d칤as vienen negativos en el dataset), se divide por el `divisor`. Luego, se eliminan los valores negativos resultantes, ya que estos suelen ser errores de codificaci칩n y se reemplazan por None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6fc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convertir_dias(data, columnas, divisor=12, redondear=True, reemplazar=False):\n",
    "    for col in columnas:\n",
    "        nueva_columna = \"CONVERTIDO_\" + str(col)\n",
    "        valores_convertidos = -data[col] / divisor\n",
    "        if redondear:\n",
    "            valores_convertidos = valores_convertidos.round()\n",
    "        valores_convertidos[valores_convertidos < 0] = None\n",
    "        if reemplazar:\n",
    "            data[col] = valores_convertidos\n",
    "        else:\n",
    "            data[nueva_columna] = valores_convertidos\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de15ad8",
   "metadata": {},
   "source": [
    "### Funci칩n para crear variables logar칤tmicas\n",
    "La funci칩n `crear_logaritmos(data, columnas, reemplazar=False)` se utiliza para aplicar una transformaci칩n logar칤tmica a una o m치s variables num칠ricas del dataset. Este tipo de transformaci칩n es com칰n cuando se trabaja con variables con distribuciones altamente sesgadas (como ingresos, montos de cr칠dito, etc.), esto se debe a que las transformaciones logar칤tmicas pueden ayudar a corregir la asimetr칤a de variables y mejorar la linealidad en modelos estad칤sticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21f7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def crear_logaritmos(data, columnas, reemplazar=False):\n",
    "    for col in columnas:\n",
    "        valores_log = np.log(data[col].abs() + 1)\n",
    "        if reemplazar:\n",
    "            data[col] = valores_log\n",
    "        else:\n",
    "            data[\"LOG_\" + str(col)] = valores_log\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ef6dd",
   "metadata": {},
   "source": [
    "### Funci칩n para crear indicadores flags de nulos\n",
    "``crear_flags_nulos(data, columnas=None)`` tiene como prop칩sito generar nuevas variables binarias (0 o 1) que indiquen si un valor estaba originalmente ausente (nulo) en el dataset. Esto con el fin de que la ausencia de valores se vuelva una informacion relevante para el modelo.\n",
    "Por ejemplo, si los clientes con ingresos faltantes tienden a incumplir, el simple hecho de no declarar el ingreso se vuelve informaci칩n sumamente relevante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4415d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crear_flags_nulos(data, columnas=None):\n",
    "    if columnas is None:\n",
    "        columnas = data.columns\n",
    "    for col in columnas:\n",
    "        if data[col].isnull().any():\n",
    "            data[\"ES_NULO_\" + str(col)] = data[col].isnull().astype(int)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c9634",
   "metadata": {},
   "source": [
    "### Funci칩n para codificar variables categ칩ricas\n",
    "Mucha de la informaci칩n que se tiene del dataset son string o cadenas de texto que el modelo no va a poder interpretar por si solo, se crea la funcion `tratar_categoricas(data)` para que a cada columna que tenga valores de tipo objeto se le reemplace cada categoria por un valor entero unico.\n",
    "Por ejemplo en la columna `GENRE` se remplazaria ``M`` por 0 y ``F`` por 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tratar_categoricas(data):\n",
    "\n",
    "    #Codifica todas las variables categ칩ricas del DataFrame usando codificaci칩n por etiquetas.\n",
    "    #Cada categor칤a 칰nica se reemplaza por un n칰mero entero 칰nico.\n",
    "\n",
    "    columnas_obj = [col for col in data.columns if data[col].dtype == \"object\"]\n",
    "    for col in columnas_obj:\n",
    "        data[col], _ = pd.factorize(data[col])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02df23",
   "metadata": {},
   "source": [
    "### 游늵 Funci칩n para calcular tasas de aprobaci칩n y rechazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31d7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcular_ratio_aprobacion(data, lags=[1, 3, 5]):\n",
    "    df = data[[\"SK_ID_CURR\", \"SK_ID_PREV\", \"DAYS_DECISION\", \"NAME_CONTRACT_STATUS\"]].copy()\n",
    "    df[\"DAYS_DECISION\"] = -df[\"DAYS_DECISION\"]\n",
    "    df = df.sort_values([\"SK_ID_CURR\", \"DAYS_DECISION\"])\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    for t in lags:\n",
    "        tmp = df.groupby(\"SK_ID_CURR\")[\"NAME_CONTRACT_STATUS_Approved\"].head(t).groupby(\"SK_ID_CURR\").mean().reset_index()\n",
    "        tmp.columns = [\"SK_ID_CURR\", f\"RATIO_APROBADO_{t}\"]\n",
    "        data = data.merge(tmp, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "        tmp = df.groupby(\"SK_ID_CURR\")[\"NAME_CONTRACT_STATUS_Refused\"].head(t).groupby(\"SK_ID_CURR\").mean().reset_index()\n",
    "        tmp.columns = [\"SK_ID_CURR\", f\"RATIO_RECHAZADO_{t}\"]\n",
    "        data = data.merge(tmp, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ce2b8",
   "metadata": {},
   "source": [
    "### 游늳 Funci칩n para agregar datos num칠ricos y categ칩ricos por cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067eeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats\n",
    "\n",
    "def agregar_por_cliente(data, id_col, etiqueta=None):\n",
    "    print(\"- Preparando el conjunto de datos...\")\n",
    "\n",
    "    categoricas = [col for col in data.columns if data[col].dtype == \"object\"]\n",
    "    datos_numericos = data.drop(columns=categoricas)\n",
    "    datos_categoricos = data[[id_col] + categoricas]\n",
    "\n",
    "    print(f\"- Variables categ칩ricas: {len(categoricas)}\")\n",
    "    print(f\"- Variables num칠ricas: {datos_numericos.shape[1] - 1}\")\n",
    "\n",
    "    # Agregaci칩n num칠rica\n",
    "    if datos_numericos.shape[1] > 1:\n",
    "        print(\"- Agregando variables num칠ricas...\")\n",
    "        numericos_agg = datos_numericos.groupby(id_col).agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "        numericos_agg.columns = [f\"{col[0]}_{col[1]}\" for col in numericos_agg.columns]\n",
    "        numericos_agg = numericos_agg.sort_index()\n",
    "    else:\n",
    "        numericos_agg = pd.DataFrame()\n",
    "\n",
    "    # Agregaci칩n categ칩rica\n",
    "    if categoricas:\n",
    "        print(\"- Agregando variables categ칩ricas...\")\n",
    "        categoricos_agg = datos_categoricos.groupby(id_col).agg({\n",
    "            col: [lambda x: scipy.stats.mode(x)[0][0], lambda x: x.nunique()]\n",
    "            for col in categoricas\n",
    "        })\n",
    "        categoricos_agg.columns = [f\"{col[0]}_{col[1]}\" for col in categoricos_agg.columns]\n",
    "        categoricos_agg = categoricos_agg.sort_index()\n",
    "    else:\n",
    "        categoricos_agg = pd.DataFrame()\n",
    "\n",
    "    # Unir\n",
    "    if not numericos_agg.empty and not categoricos_agg.empty:\n",
    "        resultado = pd.concat([numericos_agg, categoricos_agg], axis=1)\n",
    "    elif not numericos_agg.empty:\n",
    "        resultado = numericos_agg\n",
    "    else:\n",
    "        resultado = categoricos_agg\n",
    "\n",
    "    if etiqueta:\n",
    "        resultado.columns = [etiqueta + \"_\" + col for col in resultado.columns]\n",
    "\n",
    "    print(\"- Dimensiones finales:\", resultado.shape)\n",
    "    return resultado\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
