{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3372d4",
   "metadata": {},
   "source": [
    "# Configuraci贸n inicial y librer铆as\n",
    "\n",
    "Se importan las librer铆as necesarias para llevar a cabo el preprocesamiento del dataset. Este conjunto de datos requiere transformaci贸n de fechas, codificaci贸n de variables categ贸ricas, creaci贸n de nuevas caracter铆sticas y manejo de valores faltantes. A continuaci贸n, se explican brevemente las librer铆as utilizadas:\n",
    "\n",
    "- `pandas`: manipulaci贸n de datos estructurados.\n",
    "- `numpy`: operaciones num茅ricas y matem谩ticas.\n",
    "- `scipy.stats`: operaciones estad铆sticas como la moda.\n",
    "- `sklearn.preprocessing.LabelEncoder`: codificaci贸n de variables categ贸ricas.\n",
    "- `matplotlib.pyplot`: visualizaci贸n b谩sica (opcional).\n",
    "- `warnings`: suprime advertencias innecesarias en la ejecuci贸n.\n",
    "- `gc` (garbage collector): optimiza el uso de memoria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4876b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer铆as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# Se configura pandas para mostrar todas las columnas\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Ignorar advertencias\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Activar garbage collector para habilitar la recoleccion de basura, esto mejora el rendimiento en ambientes \n",
    "# que tienen un uso intensivo de memoria como lo es el caso del manejo de los datasets de la actividad desarrollada\n",
    "\n",
    "gc.enable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada1f87",
   "metadata": {},
   "source": [
    "# Funciones para el preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748dd303",
   "metadata": {},
   "source": [
    "### Funci贸n para contar valores nulos\n",
    "La funci贸n `contar_nulos(data)` permite encontrar valores faltantes en un conjunto de datos. Su objetivo es identificar qu茅 columnas tienen datos incompletos, cu谩ntos valores faltan y qu茅 porcentaje representan respecto al total de registros.\n",
    "\n",
    "Primero, calcula la cantidad total de valores nulos en cada columna utilizando `data.isnull().sum()`, que cuenta los `True` para cada celda nula. Luego, ordena estas cantidades de forma descendente para priorizar las columnas m谩s problem谩ticas.\n",
    "\n",
    "A continuaci贸n, calcula el porcentaje de nulos dividiendo cada total de nulos por el n煤mero total de filas del `DataFrame`, y multiplica por 100 para expresarlo en porcentaje. Tambi茅n se ordenan los resultados de mayor a menor.\n",
    "\n",
    "Ambas series (total y porcentaje) se combinan en un solo `DataFrame` usando `pd.concat.\n",
    "\n",
    "Por 煤ltimo, se filtran las columnas con valores nulos, devolviendo 煤nicamente aquellas que presentan al menos un valor faltante. Esto permite enfocarse exclusivamente en las variables que requieren alg煤n tipo de tratamiento durante la limpieza de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afb1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contar_nulos(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    porcentaje = (data.isnull().sum() / len(data) * 100).sort_values(ascending=False)\n",
    "    tabla = pd.concat([total, porcentaje], axis=1, keys=[\"Total de nulos\", \"Porcentaje\"])\n",
    "    return tabla[tabla[\"Total de nulos\"] > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49015e99",
   "metadata": {},
   "source": [
    "### Funci贸n convertir_dias\n",
    "La funci贸n `convertir_dias(data, columnas, divisor=12, redondear=True, reemplazar=False)` se utiliza para transformar columnas que contienen valores de tiempo expresados en d铆as negativos, como por ejemplo DAYS_BIRTH o DAYS_EMPLOYED, en unidades m谩s interpretables como meses o a帽os.\n",
    "\n",
    "El par谩metro columnas especifica la lista de variables que se desean transformar. El par谩metro `divisor` determina en qu茅 unidad se har谩 la conversi贸n (en este caso 12, para convertirlo a meses).\n",
    "\n",
    "Dentro del bucle, se invierte el signo del valor (porque los d铆as vienen negativos en el dataset), se divide por el `divisor`. Luego, se eliminan los valores negativos resultantes, ya que estos suelen ser errores de codificaci贸n y se reemplazan por None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6fc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convertir_dias(data, columnas, divisor=12, redondear=True, reemplazar=False):\n",
    "    for col in columnas:\n",
    "        nueva_columna = \"CONVERTIDO_\" + str(col)\n",
    "        valores_convertidos = -data[col] / divisor\n",
    "        if redondear:\n",
    "            valores_convertidos = valores_convertidos.round()\n",
    "        valores_convertidos[valores_convertidos < 0] = None\n",
    "        if reemplazar:\n",
    "            data[col] = valores_convertidos\n",
    "        else:\n",
    "            data[nueva_columna] = valores_convertidos\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de15ad8",
   "metadata": {},
   "source": [
    "### Funci贸n para crear variables logar铆tmicas\n",
    "La funci贸n `crear_logaritmos(data, columnas, reemplazar=False)` se utiliza para aplicar una transformaci贸n logar铆tmica a una o m谩s variables num茅ricas del dataset. Este tipo de transformaci贸n es com煤n cuando se trabaja con variables con distribuciones altamente sesgadas (como ingresos, montos de cr茅dito, etc.), esto se debe a que las transformaciones logar铆tmicas pueden ayudar a corregir la asimetr铆a de variables y mejorar la linealidad en modelos estad铆sticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21f7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def crear_logaritmos(data, columnas, reemplazar=False):\n",
    "    for col in columnas:\n",
    "        valores_log = np.log(data[col].abs() + 1)\n",
    "        if reemplazar:\n",
    "            data[col] = valores_log\n",
    "        else:\n",
    "            data[\"LOG_\" + str(col)] = valores_log\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ef6dd",
   "metadata": {},
   "source": [
    "### Funci贸n para crear indicadores flags de nulos\n",
    "``crear_flags_nulos(data, columnas=None)`` tiene como prop贸sito generar nuevas variables binarias (0 o 1) que indiquen si un valor estaba originalmente ausente (nulo) en el dataset. Esto con el fin de que la ausencia de valores se vuelva una informacion relevante para el modelo.\n",
    "Por ejemplo, si los clientes con ingresos faltantes tienden a incumplir, el simple hecho de no declarar el ingreso se vuelve informaci贸n sumamente relevante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4415d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crear_flags_nulos(data, columnas=None):\n",
    "    if columnas is None:\n",
    "        columnas = data.columns\n",
    "    for col in columnas:\n",
    "        if data[col].isnull().any():\n",
    "            data[\"ES_NULO_\" + str(col)] = data[col].isnull().astype(int)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c9634",
   "metadata": {},
   "source": [
    "### Funci贸n para codificar variables categ贸ricas\n",
    "Mucha de la informaci贸n que se tiene del dataset son string o cadenas de texto que el modelo no va a poder interpretar por si solo, se crea la funcion `tratar_categoricas(data)` para que a cada columna que tenga valores de tipo objeto se le reemplace cada categoria por un valor entero unico.\n",
    "Por ejemplo en la columna `GENRE` se remplazaria ``M`` por 0 y ``F`` por 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tratar_categoricas(data):\n",
    "\n",
    "    #Codifica todas las variables categ贸ricas del DataFrame usando codificaci贸n por etiquetas.\n",
    "    #Cada categor铆a 煤nica se reemplaza por un n煤mero entero 煤nico.\n",
    "\n",
    "    columnas_obj = [col for col in data.columns if data[col].dtype == \"object\"]\n",
    "    for col in columnas_obj:\n",
    "        data[col], _ = pd.factorize(data[col])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02df23",
   "metadata": {},
   "source": [
    "###  Funci贸n para calcular tasas de aprobaci贸n y rechazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31d7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcular_ratio_aprobacion(data, lags=[1, 3, 5]):\n",
    "    df = data[[\"SK_ID_CURR\", \"SK_ID_PREV\", \"DAYS_DECISION\", \"NAME_CONTRACT_STATUS\"]].copy()\n",
    "    df[\"DAYS_DECISION\"] = -df[\"DAYS_DECISION\"]\n",
    "    df = df.sort_values([\"SK_ID_CURR\", \"DAYS_DECISION\"])\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    for t in lags:\n",
    "        tmp = df.groupby(\"SK_ID_CURR\")[\"NAME_CONTRACT_STATUS_Approved\"].head(t).groupby(\"SK_ID_CURR\").mean().reset_index()\n",
    "        tmp.columns = [\"SK_ID_CURR\", f\"RATIO_APROBADO_{t}\"]\n",
    "        data = data.merge(tmp, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "        tmp = df.groupby(\"SK_ID_CURR\")[\"NAME_CONTRACT_STATUS_Refused\"].head(t).groupby(\"SK_ID_CURR\").mean().reset_index()\n",
    "        tmp.columns = [\"SK_ID_CURR\", f\"RATIO_RECHAZADO_{t}\"]\n",
    "        data = data.merge(tmp, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ce2b8",
   "metadata": {},
   "source": [
    "###  Funci贸n para agregar datos num茅ricos y categ贸ricos por cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067eeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats\n",
    "\n",
    "def agregar_por_cliente(data, id_col, etiqueta=None):\n",
    "    print(\"- Preparando el conjunto de datos...\")\n",
    "\n",
    "    categoricas = [col for col in data.columns if data[col].dtype == \"object\"]\n",
    "    datos_numericos = data.drop(columns=categoricas)\n",
    "    datos_categoricos = data[[id_col] + categoricas]\n",
    "\n",
    "    print(f\"- Variables categ贸ricas: {len(categoricas)}\")\n",
    "    print(f\"- Variables num茅ricas: {datos_numericos.shape[1] - 1}\")\n",
    "\n",
    "    # Agregaci贸n num茅rica\n",
    "    if datos_numericos.shape[1] > 1:\n",
    "        print(\"- Agregando variables num茅ricas...\")\n",
    "        numericos_agg = datos_numericos.groupby(id_col).agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "        numericos_agg.columns = [f\"{col[0]}_{col[1]}\" for col in numericos_agg.columns]\n",
    "        numericos_agg = numericos_agg.sort_index()\n",
    "    else:\n",
    "        numericos_agg = pd.DataFrame()\n",
    "\n",
    "    # Agregaci贸n categ贸rica\n",
    "    if categoricas:\n",
    "        print(\"- Agregando variables categ贸ricas...\")\n",
    "        categoricos_agg = datos_categoricos.groupby(id_col).agg({\n",
    "            col: [lambda x: scipy.stats.mode(x)[0][0], lambda x: x.nunique()]\n",
    "            for col in categoricas\n",
    "        })\n",
    "        categoricos_agg.columns = [f\"{col[0]}_{col[1]}\" for col in categoricos_agg.columns]\n",
    "        categoricos_agg = categoricos_agg.sort_index()\n",
    "    else:\n",
    "        categoricos_agg = pd.DataFrame()\n",
    "\n",
    "    # Unir\n",
    "    if not numericos_agg.empty and not categoricos_agg.empty:\n",
    "        resultado = pd.concat([numericos_agg, categoricos_agg], axis=1)\n",
    "    elif not numericos_agg.empty:\n",
    "        resultado = numericos_agg\n",
    "    else:\n",
    "        resultado = categoricos_agg\n",
    "\n",
    "    if etiqueta:\n",
    "        resultado.columns = [etiqueta + \"_\" + col for col in resultado.columns]\n",
    "\n",
    "    print(\"- Dimensiones finales:\", resultado.shape)\n",
    "    return resultado\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
